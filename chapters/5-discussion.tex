\chapter{Discussion}
\label{chap:discussion}

\section{Addressing the Research Questions Based on the Experiments}
\label{sec:addressing_rq_based_on_experiments}

\subsection{RQ1: How does the accuracy of the masked-autoencoder and mamba temporal action spotting model compare to existing \acrfull{sota} methods on the SoccerNet benchmark?}

Comparing the accuracy of the \acrshort{vms} (Mamba-\acrshort{s6}) model with the \acrshort{sota} \acrshort{tdeed} model on the SoccerNet benchmark reveals a nuanced picture. Based on Experiment 1, \acrshort{tdeed} achieved a higher test \acrshort{map}@50 of 47.65\%, compared to \acrshort{vms}'s 43.80\%. Both models employed postprocessing, a standard method for optimizing \acrshort{map} scores.

However, several factors complicate a direct interpretation of these final scores as a measure of inherent model superiority. Firstly, \acrshort{tdeed}'s validation performance (20.78\% \acrshort{map}@50) was significantly lower than its test score and also much lower than \acrshort{vms}'s validation \acrshort{map}@50 (48.26\%). Experiment 6 confirmed that \acrshort{tdeed}'s substantial gain from validation to test is mainly due to its specific test-time configuration, which includes \acrfull{snms} and a finer stride, a setup not used during its validation phase. This inconsistency in \acrshort{tdeed}'s own evaluation pipeline makes its validation score a less reliable indicator of its potential.

A crucial point of distinction is how \acrshort{vms} was adapted for the action spotting task. As detailed in \cref{sec:method_datasets}, \acrshort{vms} is originally an action localization model. For this thesis, it was applied to spotting by using an artificial dataset derived from the original annotations. This means \acrshort{vms} was not operating on the spotting annotations in their native form, unlike \acrshort{tdeed}. This fundamental difference in task formulation and data representation could significantly influence performance and the nature of what each model learns. The "top (k)" postprocessing used by \acrshort{vms} is also tied to this localization heritage.

Other factors contributing to the comparison include architectural differences. \acrshort{tdeed} focusing on temporal discrimination and \acrshort{vms} on long-range context. Although the belief was that long-range dependencies would use previous events to understand the current event of the game, the fine-grained attention mechanisms of \acrshort{tdeed} accurately predicted timestamps. 

The single-game validation for \acrshort{tdeed} can introduce bias to the validation. Even though Experiment 6 proved that postprocessing was a key indicator, the poor validation results for \acrshort{tdeed} can originate from a biased game. As discussed in \cref{ssec:ex1_discussion}, football games are not equal. 

Experiment 4 suggested \acrshort{vms}'s default hyperparameters are robust, \acrshort{tdeed} was not subjected to a similar hyperparameter optimization for the SoccerNet-V2 dataset, leaving its full potential under optimal tuning unexplored.

In summary, \acrshort{tdeed} scored higher on the test \acrshort{map}@50. Yet, it's difficult to declare one model definitively better. This difficulty stems from inconsistent evaluation practices and the fact that \acrshort{vms} was adapted for spotting using a modified dataset. Consequently, these results don't conclusively prove the superiority of one model architecture. The "changed dataset" approach for \acrshort{vms} is a significant factor when comparing its accuracy against \acrshort{tdeed}.


\subsection{RQ2: What are the modelâ€™s inference speed and computational requirements compared to T-DEED?}

Preprocessing time for \acrshort{vms} with \acrshort{vmae} and \acrshort{tdeed} varied greatly. Experiment 2 showed how \acrshort{vms} can offer instant inference. \acrshort{tdeed} was slower, but its inference time is decent for the context of football. It infers quicker than its input, which means real-time inference is possible. The \acrshort{vmae} preprocessing pipeline slows the practical inference time of \acrshort{vms}. 

The training time for \acrshort{vms} is less than an hour for the SoccerNet-V2 dataset. The \acrshort{tdeed} model training time is over two days. If the models only had to be trained once, this problem could be mitigated. However, in a practical application, one would probably like to correct annotations on games and add the training. Not only is the training time significant, but it requires an A100 or better \acrshort{gpu} to function. The magnitude of the time difference between inference and training makes this an investment question. Concurrently, the \acrshort{vms} works on all \acrshort{gpu}s available from IDUN. Even the heavy preprocessing of inference at \acrshort{vmae} can run on any \acrshort{gpu} as seen in \cref{tab:results_ex2}.

The key bottleneck for the \acrshort{vms} model, which prevents the apparent answer to the research question, is the \acrshort{vmae} preprocessing step. As long as this is the preprocessing timeline, \acrshort{tdeed} has the lower practical inference time. It does not help in an application that \acrshort{vms} has a super inference time, when the preprocessing is as long as it is. Alternatives to \acrshort{vmae} should be reviewed and considered in a real-world application. 

The inference and training time of \acrshort{vms} must not be looked at without being critical towards the size reduction of \acrshort{vmae}. The features loaded into the \acrshort{vms} model are significantly smaller than the folder containing all the images, which is vital for the processing time of \acrshort{tdeed}. Given the hardware-aware design of \acrfull{s6}, the \acrshort{vms}, which builds upon this, is still much quicker than a vanilla \acrfull{vit} such as \acrshort{tdeed}.

In pure model inference and training speed, \acrshort{vms} is quickest. When inferring a single unseen video, \acrshort{tdeed} is quicker. Training on \acrshort{vms} is significantly faster than \acrshort{tdeed}. The computational footprint of \acrshort{vms} is very light compared to \acrshort{tdeed}, backed by its adaptability to all types of \acrshort{gpu}s at \acrshort{idun}. 


\subsection{RQ3: Which types of adaptation can be made to the MAMBA model to increase its precision?}

% Experiment 5 showed \acrshort{tdeed} that pretraining on the older SoccerNet videos improved the prediction performance on the newer, differently annotated, SoccerNet videos. Experiment 3 demonstrated that increasing the feature dimensionality extracted from \acrshort{vmae} improved performance. The fourth experiment suggested the hyperparameter space of \acrshort{vms} models consists of several local minima, which are hard to find. Experiment 6 indicated that strong postprocessing techniques would increase a model's performance on the \acrshort{map} benchmark. 

% The experiments suggest that postprocessing is a strong avenue for model improvement. Applying \acrfull{snms} to \acrshort{vms} is a promising and relatively straightforward modification with good potential for improvement. More expressive and higher-dimensional features are more likely to increase the performance, but not by the same magnitude as the postprocessing. In addition, the masked autoencoders are customizable, and fine-tuning the models to football data can be highly influential. The nature of football videos differs from that of the Kinetics dataset. Different masking ratios are also interesting to study. 

The experiments highlighted potential adaptations for improving the \acrshort{vms} model's \acrshort{map}. Experiment 3 showed a direct performance benefit from increased dimensionality in the feature extraction. The results suggest that more expressive input features enable the Mamba architecture to diversify better, classify, and temporally predict actions. 

Experiment 5 focused on the gain in \acrshort{tdeed} when pretraining on the older SoccerNet. The games had different annotations and were from other leagues. The pretraining improved performance on the actual SoccerNet dataset, aligning with the philosophy behind transfer learning. 

Furthermore, fine-tuning \acrshort{vmae} on football data, e.g., the SoccerNet dataset, could help it extract more features. The model, which is trained on Kinetics data, is capable of extracting general representations. However, the subtle actions in football might not be distinguishable from the general representations. The downstream \acrshort{vms} can suffer potential precision loss if the features are not precise. Customizing the masked autoencoder in other ways, such as adjusting the masking ratio based on football video characteristics, could also be beneficial. 

The postprocessing techniques highlighted in Experiment 6 are applied in both models. The efficiency of a $topk$ postprocessing must be evaluated, as Experiment 1 demonstrated that it didn't work as intended on a dense, action-filled video. Although postprocessing techniques could yield gains, the primary improvements might lie in the feature representation and feature extraction. 

Another postprocessing technique that could be utilized is the overlapping of clips or feature vectors. If the dataset is split into overlapping clips, the events at the start and end would have more context. Overlapping clips also give the model double opportunities to detect actions.

Finally, the hyperparameter sweep indicated a complex hyperparameter space for \acrshort{vms}. It suggested the default parameters offer a valuable baseline. Careful tuning might lead to marginal gains, but it did not seem to yield fundamental changes. 

To summarize, the most promising adaptations for \acrshort{vms} appear to be related to the input features. Increasing their dimensionality and relevance to the dataset.  Postprocessing and hyperparameter tuning can further improve the results, but enhancing the quality of relevance of the features is more likely to improve \acrshort{map} substantially.


\section{Limitations}


The first limitation arises from the fundamental difference between action localization and action spotting. \acrshort{vms} is an action localization model, \acrshort{tdeed} is an action spotting model. The artificial dataset is derived from the original dataset and used to train \acrshort{vms}. The \acrshort{vms} model predicts 2-second localizations while the \acrshort{tdeed} model predicts a single frame. There is an inherent difference here that makes comparison more challenging. The changed dataset approach was a pragmatic choice, which could impact performance. 

The dataset and splitting are created greedily. As the new dataset is split into equal 1-minute segments, it does not take into consideration when actions happen or what happens at the start and end. This causes actions to appear at the beginning or end of a video, effectively removing half of the context of the actions. A sliding window or other methods could be used to mitigate this. 

The \acrshort{vmae} feature extractor was used without fine-tuning on the specific dataset. As discussed in RQ3, it is pretrained on a general video dataset. Domain-specific pretraining could significantly enhance the downstream prediction precision of \acrshort{vms}. According to its authors, \textit{" It takes more than two weeks to pre-train a ViT-g model with VideoMAE on 64 A100 \acrshort{gpu}s"}\cite{wang_videomae_2023}. In the related GitHub, they assign just half the \acrshort{gpu}s, 32, to perform the fine-tuning. This is a practical constraint due to the limited time of a thesis. Using the extracted data in the baseline is not feasible. \acrshort{tdeed} uses subtle differences from frames to provide exact timestamps. 

The experiments did not cover tests on \acrfull{rbk} data. No labeled data existed, so a dataset must be created from scratch. 

The SoccerNet dataset has a skewed event distribution. Effectively, the models can be a pass-and-drive predictor, whose annotations make up $>74\%$ of the actions. The evaluation of models does not take this into account when calculating results, which means actions such as "goal" or "free kick" are unlikely to be spotted. The data in the SoccerNet V2 dataset is not that generalizable. All games, bar one, are played on the same day. The exception is played the day after. This means likely similar weather conditions. They are from the same league, where camera positions are equal. Additionally, as discussed in sustainability, there are only male games. 

The usage of V100 \acrshort{gpu}s in Experiment 2 for \acrshort{vmae} extraction, opposed to the A100 \acrshort{gpu} for \acrshort{tdeed}, affects the direct comparison of the processing times. However, this difference was of a magnitude that the changes achieved by using different \acrshort{gpu}s would not significantly affect the result. 

Finally, the scope of hyperparameter optimization for \acrshort{tdeed} was limited. It was evaluated using its default parameters. A hyperparameter sweep for \acrshort{tdeed} similar to that performed for \acrshort{vms} (Experiment 4) was not undertaken. Its peak performance on this specific dataset might not have been reached. 

\section{Reflections}

I was disappointed that the \acrfull{s6} did not outperform the \acrshort{sota} \acrshort{tdeed} implementation when trained on the same dataset. I was confident from the literature review that the \acrshort{s6} would excel on the task, given its limited training data. I believe MAMBA is an underexplored technology within the context of sports\cite{survey_of_survey} and, in particular, football\cite{seweryn_survey_2023}. RDFA-S6\cite{lee_enhancing_mamba_s6_2024} results on \acrshort{sota} benchmarks in \acrshort{tal} underlie the statement. Additionally, the rapid scaling of \acrshort{s6} and its low data consumption compared to \acrfull{vit} should enable it to learn patterns from limited data quickly. This is particularly useful for teams that annotate their data; in the football environment, it is not common to share annotations. The literature study consisted of only one article from a professional football club, Liverpool. And more clubs are using it, according to the \acrshort{rbk} coaches. 

I have a few theories as to why the desired results were not achieved. Primarily, I think the feature extraction loses some essential features. Because the football actions are very subtle in most cases, I believe the pretrained \acrshort{vmae} is unable to focus on those segments. Secondly, I think the adaptation of the action localization framework of \acrshort{vms} to the spotting task might have been suboptimal. Some information may be altered during the translation process. A 2-second segment contains more information than a single timestamp. This could confuse the model, but also strengthen it. 

Regarding the workflow, I had daily standup meetings with myself. They were quite helpful in showing where the most time was spent, and the results align with my beliefs. The majority of the work involved programming, followed by writing, reading, meetings, and other tasks. Debugging and setting up MAMBA took longer than I expected. As did attempting to create a model from scratch rather than implementing an existing one. Creating a model from scratch was not worth the effort. 

Dealing with the technical \acrshort{gpu} issues and \acrshort{idun} issues when implementing the hardware-aware parts of MAMBA, I must have done either way. It took a long time, as the language (*.cu) and the error messages were unfamiliar to me. The problems became difficult to break down into more minor, manageable issues and, therefore, challenging to solve. 

The stress of the models not being easy to implement hindered the methodical approach I made in a plan to solve the master's thesis. Ideally, the process of conducting experiments should have started earlier, allowing me to approach the problem more iteratively. Experimenting, finding its shortcomings, researching the method to solve the problem, and then designing and doing a new experiment. Repeat. The method is as important, if not even more important, than the results. For instance, with hyperparameters, I selected new ranges based on what I observed in \acrfull{wandb}. I think the experiment would have been stronger if there were an algorithm that could explicitly design new ranges based on results.

\section{Sustainability}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/un_poster.jpg}
    \caption{The UN sustainability goals. The content of this publication has not been approved by the United Nations and does not reflect the views of the United Nations or its officials or Member States. The goals can be found at: \url{https://www.un.org/sustainabledevelopment}.}
    \label{fig:sdg}
\end{figure}

Working with video data, especially with \acrshort{vit}s, raises concerns about the environmental footprint. I will not concern myself with the footprint related to the production of \acrshort{gpu}s, but rather with their high energy consumption. Addressing sustainability in this context aligns with several \acrfull{sdg}, notably \acrshort{sdg} 9 (Industry, Innovation, and Infrastructure) by promoting efficient technologies, \acrshort{sdg} 12 (Responsible Consumption and Production) by minimizing computational waste, and \acrshort{sdg} 13 (Climate Action) by reducing energy demands. All the sustainability goals can be seen in \cref{fig:sdg}

Experiment 2 shows how much more efficient the \acrshort{s6} model is compared to a \acrshort{vit} for training. The difference between 1 hour and $\approx55$ hours is significant, and when conducting several experiments, this is an excellent argument for choosing \acrshort{ssm}s over \acrshort{vit}s. The difference in training time translates directly to power consumption. If you add to the equation that the \acrshort{vms} model can run on older \acrshort{gpu}s, that lowers the power consumption even more. And it allows for fairer \acrfull{ai} development, since the barrier of entry is lower. It promotes equality. 

I have used over 5000 hours of compute time on this master, most of it on the \acrlong{vit}s \acrshort{vmae} and \acrshort{tdeed}. Most of these hours are not at 100$\%$ capacity, but the environmental footprint this master has left behind is significant. If 100$\%$ power usage is assumed, and an electric car uses $15\frac{kWh}{100km}$. With the energy from running 5000 hours on A100 \acrshort{gpu}s, the vehicle could drive $\approx10,000 km$. \info{most of this came from doing masked autoencoding of all 500 videos, which weren't used in the end. }

The SoccerNet V2 dataset consists of all 507 male games. \acrshort{sdg} 5 (Gender Equality) is not addressed at all in the dataset. There is no female representation. This is stupid, even from a technical view. The rules are the same, the actions are the same, and the pitches are the same. Including female games could enhance model generalizability by exposing it to a broader range of player physiques, movement styles, and game dynamics. The inclusion of female sports data encourages more professional women's teams to adopt and benefit from these analytical tools. Underrepresentation in datasets is a well-documented issue in data science, often leading to biased models that perform less effectively for underrepresented groups. Addressing this gap in sports analytics datasets, such as SoccerNet, is a step towards more equitable and ultimately more effective \acrshort{ai}.