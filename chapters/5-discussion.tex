\chapter{Discussion}
\label{chap:discussion}

\section{Addressing the Research Questions Based on the Experiments}
\label{sec:addressing_rq_based_on_experiments}

\subsection{RQ1: How does the accuracy of the masked-autoencoder and mamba temporal action spotting model compare to existing \acrlong{sota} methods on the SoccerNet benchmark?}


Based on Experiment 1, \acrshort{vms} showed a significantly better validation accuracy than the \acrshort{tdeed}. However,  doubts were raised regarding these results when the testing \acrshort{map} of \acrshort{tdeed} was examined. Experiment 6 demonstrated a significant difference in accuracy when applying \acrfull{snms} compared to the testing. 

With the current experiments, it isn't easy to come to a clear conclusion on which model is better. The most significant limitation is the absence of a test \acrshort{map}@50 score for the \acrshort{vms} model (as stated in \cref{ssec:ex1_results} and \cref{ssec:ex1_discussion}). \acrshort{tdeed}'s test \acrshort{map}@50 is 47.65\%, but there's no equivalent \acrshort{vms} metric to compare against directly on unseen test data. Experiment 6 shows the impact of the postprocessing step and explains why it is necessary for a competitive \acrshort{map} score. Because the models use different postprocessing, it is not evident how much they contribute compared to the model. 

In a hypothetical scenario, where the difference between validation, as shown in \cref{fig:ex6:no_pp_val}, and its test results, in \cref{fig:ex6:no_pp_test}, allows us to compute the validation score from a test score. In Experiment 6, the increase was \(\approx10\%\), giving the baseline a \acrshort{map} of $58\%$. However, because the impacts of postprocessing on \acrshort{vms} are not fully known, it is unwise to infer this.

Another significant contribution to the difficulty in comparison is the nature of the \acrshort{vms}, which involves action localization, while \acrshort{tdeed} focuses on action spotting. This is why the postprocessing differs and is difficult to compare directly. \acrshort{vms} works on an \textit{artificial dataset} as explained in \cref{sec:method_datasets}. In future work, the input and output layers of \acrshort{vms} should be changed. 

Based on the experiments, it is difficult to make a definitive statement about which model is more accurate. The \acrshort{tdeed} model achieved a test \acrshort{map}@50 of 47.65\% (Experiment 1). This result was obtained using \acrfull{snms} postprocessing and a prediction stride of 1. The \acrshort{vms} (Mamba-\acrshort{s6}) model achieved a validation \acrshort{map}@50 of 43.62\% (Experiment 1). This result used a "top (k)" postprocessing method. The \acrshort{vms} model was not evaluated on the test set. Experiment 6 demonstrated that \acrshort{tdeed}'s performance is highly dependent on \acrshort{snms}; without it, its test \acrshort{map}@50 dropped to 13.62\% (at stride 1). \acrshort{tdeed}'s validation \acrshort{map}@50 in Experiment 1 was 20.78\% (stride 2, no \acrshort{snms}).

\subsection{RQ2: What are the modelâ€™s inference speed and computational requirements compared to T-DEED?}

Preprocessing time for \acrshort{vms} with \acrshort{vmae} and \acrshort{tdeed} varied greatly. Experiment 2 showed how \acrshort{vms} can offer instant inference. \acrshort{tdeed} was slower, but its inference time is decent for the context of football. It infers quicker than its input, which means real-time inference is possible. The \acrshort{vmae} preprocessing pipeline slows the practical inference time of \acrshort{vms}. 

The training time for \acrshort{vms} is less than an hour for the SoccerNet-V2 dataset. The \acrshort{tdeed} model training time is over two days. If the models only had to be trained once, this problem could be mitigated. However, in a practical application, one would probably like to correct annotations on games and add the training. Not only is the training time significant, but it requires an A100 or better \acrshort{gpu} to function. The magnitude of the time difference between inference and training makes this an investment question. Concurrently, the \acrshort{vms} works on all \acrshort{gpu}s available from IDUN. Even the heavy preprocessing of inference at \acrshort{vmae} can run on any \acrshort{gpu} as seen in \cref{tab:results_ex2}.

The key bottleneck for the \acrshort{vms} model, which prevents the apparent answer to the research question, is the \acrshort{vmae} preprocessing step. As long as this is the preprocessing timeline, \acrshort{tdeed} has the lower practical inference time. It does not help in an application that \acrshort{vms} has a super inference time, when the preprocessing is as long as it is. Alternatives to \acrshort{vmae} should be reviewed and considered in a real-world application. 

The inference and training time of \acrshort{vms} must not be looked at without being critical towards the size reduction of \acrshort{vmae}. The features loaded into the \acrshort{vms} model are significantly smaller than the folder containing all the images, which is vital for the processing time of \acrshort{tdeed}. Given the hardware-aware design of \acrfull{s6}, the \acrshort{vms}, which builds upon this, is still much quicker than a vanilla \acrfull{vit} such as \acrshort{tdeed}.

In pure model inference and training speed, \acrshort{vms} is quickest. When inferring a single unseen video, \acrshort{tdeed} is quicker. Training on \acrshort{vms} is significantly faster than \acrshort{tdeed}. The computational footprint of \acrshort{vms} is very light compared to \acrshort{tdeed}, backed by its adaptability to all types of \acrshort{gpu}s at \acrshort{idun}. 


\subsection{RQ3: Which types of adaptation can be made to the MAMBA model to increase its precision?}

Experiment 5 showed \acrshort{tdeed} that pretraining on the older SoccerNet videos improved the prediction performance on the newer, differently annotated, SoccerNet videos. Experiment 3 demonstrated that increasing the feature dimensionality extracted from \acrshort{vmae} improved performance. The fourth experiment suggested the hyperparameter space of \acrshort{vms} models consists of several local minima, which are hard to find. Experiment 6 indicated that strong postprocessing techniques would increase a model's performance on the \acrshort{map} benchmark. 

The experiments suggest that postprocessing is a strong avenue for model improvement. Applying \acrfull{snms} to \acrshort{vms} is a promising and relatively straightforward modification with good potential for improvement. More expressive and higher-dimensional features are more likely to increase the performance, but not by the same magnitude as the postprocessing. In addition, the masked autoencoders are customizable, and fine-tuning the models to football data can be highly influential. The nature of football videos differs from that of the Kinetics dataset. Different masking ratios are also interesting to study. 

\section{Limitations}

The most significant drawback that is repeatedly mentioned throughout the discussions is the difference in nature between the compared models and the difficulties in comparing metrics. Direct comparison is difficult because they do not work on the same data. \acrfull{tal} and action spotting fundamentally differ in the temporal spotting domain. The annotation edit to fit the spotting annotations for the \acrshort{tal} domain can remove information about the action. This was necessary to run the model within the scope of this thesis, but a two-second segment with the action in the middle differs from a single frame with an action. 

The \acrshort{vmae} feature extractor was used without fine-tuning on the specific football dataset or for the action spotting task. Although Experiment 6 demonstrated that general pre-training is beneficial, fine-tuning the \acrshort{vmae} model on football data was not conducted. According to its authors, \textit{" It takes more than two weeks to pre-train a ViT-g model with VideoMAE on 64 A100 \acrshort{gpu}s"}\cite{wang_videomae_2023}. In the related GitHub, they assign just half the \acrshort{gpu}s, 32, to perform the fine-tuning. 

The experiments did not cover tests on \acrfull{rbk} data. No labeled data existed, so a dataset must be created from scratch. 

The dataset has a highly skewed event distribution, and the models struggle to predict low-frequency events, such as goals. Predicting actions on the edges of 1-minute videos was achieved by having them span one second before and after the start and end of the video. This could slightly alter the results of the prediction of \acrshort{vms}, but in the current environment, it does not have the highest priority. 

The usage of V100 \acrshort{gpu}s in Experiment 2 for \acrshort{vmae} extraction, opposed to the A100 \acrshort{gpu} for \acrshort{tdeed}, affects the direct comparison of the processing times. However, this difference was of a magnitude that the changes achieved by using different \acrshort{gpu}s would not significantly affect the result. 

\section{Reflections}

I was disappointed that the \acrfull{s6} did not outperform the \acrshort{sota} \acrshort{tdeed} implementation when trained on the same dataset. I was confident from the literature review that the \acrshort{s6} would excel on the task, given its limited training data. I believe MAMBA is an underexplored technology within the context of sports\cite{survey_of_survey} and, in particular, football\cite{seweryn_survey_2023}. RDFA-S6\cite{lee_enhancing_mamba_s6_2024} results on \acrshort{sota} benchmarks in \acrshort{tal} underlie the statement. Additionally, the rapid scaling of \acrshort{s6} and its low data consumption compared to \acrfull{vit} should enable it to learn patterns from limited data quickly. This is particularly useful for teams that annotate their data; in the football environment, it is not common to share annotations. The literature study consisted of only one article from a professional football club, Liverpool. And more clubs are using it, according to the \acrshort{rbk} coaches. 

I have a few theories as to why the desired results were not achieved. Primarily, I think the feature extraction loses some essential features. Because the football actions are very subtle in most cases, I believe the pretrained \acrshort{vmae} is unable to focus on those segments. Secondly, I think the adaptation of the action localization framework of \acrshort{vms} to the spotting task might have been suboptimal. Some information may be altered during the translation process. A 2-second segment contains more information than a single timestamp. This could confuse the model, but also strengthen it. 

Regarding the workflow, I had daily standup meetings with myself. They were quite helpful in showing where the most time was spent, and the results align with my beliefs. The majority of the work involved programming, followed by writing, reading, meetings, and other tasks. Debugging and setting up MAMBA projects took longer than they should have, as did attempting to create a model from scratch rather than implementing an existing one. Creating a model from scratch was not worth the effort. Dealing with the technical \acrshort{gpu} issues and \acrshort{idun} issues when implementing the hardware-aware parts of MAMBA, I must have done either way. It took a long time, as the language (*.cu) and the error messages were unfamiliar to me. The problems became difficult to break down into more minor, manageable issues, and therefore challenging to solve. 

The stress of the models not being easy to implement hindered the methodical approach I made in a plan to solve the master's thesis. Ideally, the process of conducting experiments should have started earlier, allowing me to approach the problem more iteratively. Experimenting, finding its shortcomings, researching the method to solve the problem, and then designing and doing a new experiment. Repeat. The method is as important, if not even more important, than the results. For instance, with hyperparameters, I selected new ranges based on what I observed in \acrfull{wandb}. I think the experiment would have been stronger if there were an algorithm that could explicitly design new ranges based on results.

\section{Sustainability}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/un_poster.jpg}
    \caption{The UN sustainability goals. The content of this publication has not been approved by the United Nations and does not reflect the views of the United Nations or its officials or Member States. The goals can be found at: \url{https://www.un.org/sustainabledevelopment}.}
    \label{fig:sdg}
\end{figure}

Working with video data, especially with \acrshort{vit}s, raises concerns about the environmental footprint. I will not concern myself with the footprint related to the production of \acrshort{gpu}s, but rather with their high energy consumption. Addressing sustainability in this context aligns with several \acrfull{sdg}, notably \acrshort{sdg} 9 (Industry, Innovation, and Infrastructure) by promoting efficient technologies, \acrshort{sdg} 12 (Responsible Consumption and Production) by minimizing computational waste, and \acrshort{sdg} 13 (Climate Action) by reducing energy demands. All the sustainability goals can be seen in \cref{fig:sdg}

Experiment 2 shows how much more efficient the \acrshort{s6} model is compared to a \acrshort{vit} for training. The difference between 1 hour and $\approx55$ hours is significant, and when conducting several experiments, this is an excellent argument for choosing \acrshort{ssm}s over \acrshort{vit}s. The difference in training time translates directly to power consumption. If you add to the equation that the \acrshort{vms} model can run on older \acrshort{gpu}s, that lowers the power consumption even more. And it allows for fairer \acrfull{ai} development, since the barrier of entry is lower. It promotes equality. 

I have used over 5000 hours of compute time on this master, most of it on the \acrlong{vit}s \acrshort{vmae} and \acrshort{tdeed}. Most of these hours are not at 100$\%$ capacity, but the environmental footprint this master has left behind is significant. If 100$\%$ power usage is assumed, and an electric car uses $15\frac{kWh}{100km}$. With the energy from running 5000 hours on A100 \acrshort{gpu}s, the vehicle could drive $\approx10,000 km$. \info{most of this came from doing masked autoencoding of all 500 videos, which weren't used in the end. }

The SoccerNet V2 dataset consists of all 507 male games. \acrshort{sdg} 5 (Gender Equality) is not addressed at all in the dataset. There is no female representation. This is stupid, even from a technical view. The rules are the same, the actions are the same, and the pitches are the same. Including female games could enhance model generalizability by exposing it to a broader range of player physiques, movement styles, and game dynamics. The inclusion of female sports data encourages more professional women's teams to adopt and benefit from these analytical tools. Underrepresentation in datasets is a well-documented issue in data science, often leading to biased models that perform less effectively for underrepresented groups. Addressing this gap in sports analytics datasets, such as SoccerNet, is a step towards more equitable and ultimately more effective \acrshort{ai}.