\chapter{Discussion}
\label{chap:discussion}

\section{Addressing the Research Questions Based on the Experiments}
\info{Quantitative results vs. baselines}
\info{Ablations on clip length, masking ratio, MAMBA variants}
\info{Error analysis / qualitative examples}


\subsection{\textbf{RQ1}:
How does the accuracy of the masked-autoencoder and mamba temporal action spotting model compare to existing \acrlong{sota} methods on the SoccerNet benchmark?}

With the current experiments, it is difficult to come to a clear conclusion on which model is better. Results indicate that \acrfull{tdeed} performs better, with \acrshort{vms} not living up to standards. This conclusion is reached by looking at the drop between validation, found in \cref{fig:ex6:no_pp_val}, and its test results shown in \cref{fig:ex6:no_pp_test}. The test results are significantly lower than the validation epoch. Therefore, looking at \cref{tab:results_ex1}, where the test results of \acrshort{tdeed} outperform the validation results found in \acrshort{vms}. It is inferred that the real validation using postprocessing would significantly outperform the \acrshort{vms}. 

This does not tell the true story. 

haven't done justice to the comparison


\subsection{RQ2:} 
What are the modelâ€™s inference speed and computational requirements compared to T-DEED?

add video-mae to the time is fair, as it contributes to the results

inference with tdeed much faster because of videomae before mamba


\subsection{RQ3:}
Which types of adaptation can be made to the MAMBA model to increase its precision?

Hyperparameters were configured from before, quite well. 
They might be suited to the feature extracted and not mamba directly. 
future Experiment with this


plot to check if it predicts equal amount of actions at all times, eg doesnt ignore first and last second 

\section{Limitations}
didnt fine tune the feature extractor
didnt test on rbk data
no pretraining
1 second fail margin of sn doesnt apply to actions in edge cases, but they are stricter. 
skewed distribution of events, even full tdeed training cant predict goal with correct team

\section{Reflections}
mamba should be explored more in the sports action recognition based on litareture review and results. 
a lot of time was spent debugging and setting up the project to run with mamba. 
registered for the competition
asked for too little help. didnt use either github nor discord nor supervisors very much
should have designed a math formula for hyperparameter optimalization
had daily standups with myself, those were useful. especially to see what took a lot of time, what blocked me.
trying to make my own model from scratch was a waste of time
could it be erronous that all clips have the same size because of the last clips in each game not having
i want to build my own simpler model :) and understand the whole process
significant impact of postprocessing in tdeed
understand more about suppression with the map score
vms runs on any GPU, but tdeed needs a lot of memory and only runs on premium GPUs.
could sit here and add up increases and pretend it would be the predicted results of an increased, but no value without experiments
hard to say how much info is gained/lost from video mae

\section{Sustainability}
VideoMAE is not very good. MAMBA in itself is nice. if you calculate power. i can do something similar with power need as done in visual intelligence, but i do not have all the data in wandb now. 